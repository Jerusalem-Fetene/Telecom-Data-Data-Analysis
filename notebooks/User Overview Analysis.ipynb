{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - User Overview Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using pandas we can group the data by user_id and aggregate the required metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Aggregate user behavior\n",
    "user_behavior = df.groupby('user_id').agg(\n",
    "    number_of_xdr_sessions=('session_id', 'count'),\n",
    "    total_session_duration=('session_duration', 'sum'),\n",
    "    total_download_data=('download_data', 'sum'),\n",
    "    total_upload_data=('upload_data', 'sum'),\n",
    "    total_data_volume=('data_volume', 'sum')  # Assuming 'data_volume' is already in Bytes\n",
    ").reset_index()\n",
    "\n",
    "# Display the aggregated user behavior\n",
    "print(user_behavior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Describe data types and relevant variables\n",
    "data_info = df.dtypes\n",
    "data_description = df.describe(include='all')\n",
    "\n",
    "# Display information\n",
    "print(data_info)\n",
    "print(data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment users into decile classes based on total session duration\n",
    "df['total_session_duration'] = df.groupby('user_id')['session_duration'].transform('sum')\n",
    "df['decile_class'] = pd.qcut(df['total_session_duration'], 5, labels=False)\n",
    "\n",
    "# Compute total data (DL + UL) per decile class\n",
    "data_per_decile = df.groupby('decile_class').agg(\n",
    "    total_data_per_decile=('download_data', 'sum') + ('upload_data', 'sum')\n",
    ").reset_index()\n",
    "print(data_per_decile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the basic metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic metrics\n",
    "basic_metrics = df[['session_duration', 'download_data', 'upload_data']].agg(['mean', 'median', 'std', 'min', 'max'])\n",
    "print(basic_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Non-Graphical Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispersion parameters\n",
    "dispersion_metrics = df[['session_duration', 'download_data', 'upload_data']].agg(['mean', 'median', 'std', 'min', 'max', 'var'])\n",
    "print(dispersion_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Graphical Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Histograms for quantitative variables\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, column in enumerate(['session_duration', 'download_data', 'upload_data']):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    sns.histplot(df[column], bins=30, kde=True)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate analysis between applications and total DL+UL data\n",
    "applications = ['Social Media', 'Google', 'Email', 'YouTube', 'Netflix', 'Gaming', 'Other']\n",
    "for app in applications:\n",
    "    sns.scatterplot(data=df, x=app, y='download_data' + 'upload_data')\n",
    "    plt.title(f'Relationship between {app} and Total Data (DL+UL)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "correlation_matrix = df[applications].corr()\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix of Applications')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Select features for PCA\n",
    "features = df[applications]\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(features)\n",
    "\n",
    "# Create a DataFrame with the principal components\n",
    "pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "print(pca_df.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
